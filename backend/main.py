import json
import time
from typing import Generator
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from langchain_core.messages import HumanMessage

# ëª¨ë“ˆ ì„í¬íŠ¸
from schemas import ChatRequest
from graph import app_graph

# [ì¶”ê°€ë¨] Frontendì—ì„œ ê°€ì ¸ì˜¨ ìœ ì € ë¼ìš°í„°
from routers import users

app = FastAPI(title="Perfume Re-Act Chatbot")

# [ì¶”ê°€ë¨] ìœ ì € ë¼ìš°í„° ë“±ë¡ (ë¡œê·¸ì¸/íšŒì›ê°€ì… ê¸°ëŠ¥ í™œì„±í™”)
app.include_router(users.router)

# CORS ì„¤ì •
origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# =================================================================
# í•µì‹¬ ë¡œì§: ìŠ¤íŠ¸ë¦¼ ì œë„ˆë ˆì´í„° (Backendì˜ ìµœì‹  v2 ë¡œì§ ìœ ì§€)
# =================================================================
async def stream_generator(
    user_query: str, thread_id: str
) -> Generator[str, None, None]:
    config = {"configurable": {"thread_id": thread_id}}
    inputs = {"messages": [HumanMessage(content=user_query)]}

    try:
        async for event in app_graph.astream_events(
            inputs, config=config, version="v2"
        ):
            kind = event["event"]
            metadata = event.get("metadata", {})
            node_name = metadata.get("langgraph_node", "")

            # ---------------------------------------------------------
            # [A] Writer: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (WriterëŠ” ì¼ë°˜ í…ìŠ¤íŠ¸ì´ë¯€ë¡œ OK)
            # ---------------------------------------------------------
            if kind == "on_chat_model_stream":
                # interviewerë¥¼ ì—¬ê¸°ì„œ ì œì™¸! (JSON ë…¸ì¶œ ë°©ì§€)
                if node_name == "writer":
                    content = event["data"]["chunk"].content
                    if content:
                        data = json.dumps(
                            {"type": "answer", "content": content}, ensure_ascii=False
                        )
                        yield f"data: {data}\n\n"

            # ---------------------------------------------------------
            # [B] Interviewer: ìƒê°(JSON)ì´ ëë‚˜ë©´ ê²°ê³¼ ë©”ì‹œì§€ë§Œ ì „ì†¡
            # ---------------------------------------------------------
            elif kind == "on_chain_end" and node_name == "interviewer":
                # Interviewer ë…¸ë“œ ì‹¤í–‰ì´ ì™„ë£Œëœ ì‹œì ì˜ ì¶œë ¥ì„ ì¡ìŠµë‹ˆë‹¤.
                output = event["data"].get("output")

                # ë©”ì‹œì§€ê°€ ì¡´ì¬í•œë‹¤ë©´ (ì¶”ê°€ ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš°)
                if output and isinstance(output, dict):
                    messages = output.get("messages")
                    if messages and len(messages) > 0:
                        last_msg = messages[-1]
                        # ìµœì¢… ì§ˆë¬¸ ë‚´ìš©ë§Œ ê¹”ë”í•˜ê²Œ ì „ì†¡
                        if hasattr(last_msg, "content") and last_msg.content:
                            data = json.dumps(
                                {"type": "answer", "content": last_msg.content},
                                ensure_ascii=False,
                            )
                            yield f"data: {data}\n\n"

            # ---------------------------------------------------------
            # [C] Researcher (ë¡œê·¸): ë„êµ¬ ì‚¬ìš© ì•Œë¦¼
            # ---------------------------------------------------------
            elif kind == "on_chat_model_end" and node_name == "researcher":
                output = event["data"].get("output")
                if output and hasattr(output, "tool_calls") and output.tool_calls:
                    tool_name = output.tool_calls[0]["name"]
                    log_msg = f"ğŸ” [ê²€ìƒ‰ ì¤‘] {tool_name} ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
                    data = json.dumps(
                        {"type": "log", "content": log_msg}, ensure_ascii=False
                    )
                    yield f"data: {data}\n\n"

            # ---------------------------------------------------------
            # [D] Tools (ë¡œê·¸): ë°ì´í„° ì¡°íšŒ ì™„ë£Œ
            # ---------------------------------------------------------
            elif kind == "on_chain_end" and node_name == "tools":
                log_msg = "âœ… ë°ì´í„° ì¡°íšŒ ì™„ë£Œ! ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."
                data = json.dumps(
                    {"type": "log", "content": log_msg}, ensure_ascii=False
                )
                yield f"data: {data}\n\n"

    except GeneratorExit:
        print(f"ğŸ‘‹ Client disconnected (Thread: {thread_id})")
        return
    except Exception as e:
        print(f"ğŸš¨ Server Error: {e}")
        error_msg = json.dumps({"type": "error", "content": str(e)}, ensure_ascii=False)
        yield f"data: {error_msg}\n\n"


@app.get("/health")
def health():
    return {"status": "ok"}


@app.post("/chat")
async def chat_stream(request: ChatRequest):
    return StreamingResponse(
        stream_generator(request.user_query, request.thread_id),
        media_type="text/event-stream",
    )


if __name__ == "__main__":
    import uvicorn

    # ë„ì»¤ ë‚´ë¶€ì—ì„œëŠ” 0.0.0.0ìœ¼ë¡œ ì—´ì–´ì•¼ ì™¸ë¶€(í˜¸ìŠ¤íŠ¸/í”„ë¡ íŠ¸)ì—ì„œ ì ‘ì† ê°€ëŠ¥
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
