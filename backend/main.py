import json
import time
from typing import Generator, List
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from fastapi.staticfiles import StaticFiles
import os

# [ìˆ˜ì •] AIMessage ì¶”ê°€ ì„í¬íŠ¸
from langchain_core.messages import HumanMessage, AIMessage

# ëª¨ë“ˆ ì„í¬íŠ¸
from agent.schemas import ChatRequest
from agent.graph import app_graph

# [ì¶”ê°€] DB ê´€ë ¨ í•¨ìˆ˜ ì„í¬íŠ¸
from agent.database import save_chat_message, get_chat_history, get_user_chat_list

# Frontendì—ì„œ ê°€ì ¸ì˜¨ ìœ ì € ë¼ìš°í„°
from routers import users

app = FastAPI(title="Perfume Re-Act Chatbot")

uploads_dir = os.path.join(os.getcwd(), "uploads")
os.makedirs(uploads_dir, exist_ok=True)
app.mount("/uploads", StaticFiles(directory=uploads_dir), name="uploads")

# ìœ ì € ë¼ìš°í„° ë“±ë¡
app.include_router(users.router)

# CORS ì„¤ì •
origins = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# =================================================================
# í•µì‹¬ ë¡œì§: ìŠ¤íŠ¸ë¦¼ ì œë„ˆë ˆì´í„° (History ì €ì¥ ë° ë³µì› ë¡œì§ ì¶”ê°€)
# =================================================================
async def stream_generator(
    user_query: str, thread_id: str, member_id: int = 0
) -> Generator[str, None, None]:

    # [1] ì‚¬ìš©ì ë©”ì‹œì§€ DB ì €ì¥ (User Turn)
    # -----------------------------------------------------------
    save_chat_message(thread_id, member_id, "user", user_query)
    # -----------------------------------------------------------

    config = {"configurable": {"thread_id": thread_id}}

    # [2] ë¬¸ë§¥ ë³µì›: DBì—ì„œ í•´ë‹¹ ìŠ¤ë ˆë“œì˜ ê³¼ê±° ëŒ€í™” ë‚´ì—­ ë¡œë“œ
    # -----------------------------------------------------------
    db_history = get_chat_history(thread_id)
    restored_messages = []

    for msg in db_history:
        # í˜„ì¬ ë³´ë‚¸ ì§ˆë¬¸ì´ DBì— ì´ë¯¸ ë“¤ì–´ê°”ìœ¼ë¯€ë¡œ ì¤‘ë³µ ë°©ì§€
        if msg["role"] == "user" and msg["text"] == user_query:
            continue

        if msg["role"] == "user":
            restored_messages.append(HumanMessage(content=msg["text"]))
        else:
            restored_messages.append(AIMessage(content=msg["text"]))

    # ê³¼ê±° ë‚´ì—­ + í˜„ì¬ ì§ˆë¬¸ì„ í•©ì³ì„œ ê·¸ë˜í”„ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬
    inputs = {
        "messages": restored_messages + [HumanMessage(content=user_query)],
        "member_id": member_id,
    }
    # -----------------------------------------------------------

    # AI ë‹µë³€ ì „ì²´ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ëˆ„ì  ë³€ìˆ˜
    full_ai_response = ""

    try:
        async for event in app_graph.astream_events(
            inputs, config=config, version="v2"
        ):
            kind = event["event"]
            metadata = event.get("metadata", {})
            node_name = metadata.get("langgraph_node", "")

            # [A] Writer: ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
            if kind == "on_chat_model_stream":
                if node_name == "writer":
                    content = event["data"]["chunk"].content
                    if content:
                        full_ai_response += content  # ë‹µë³€ ëˆ„ì 
                        data = json.dumps(
                            {"type": "answer", "content": content}, ensure_ascii=False
                        )
                        yield f"data: {data}\n\n"

            # [B] Interviewer: ê²°ê³¼ ì „ì†¡
            elif kind == "on_chain_end" and node_name == "interviewer":
                output = event["data"].get("output")
                if output and isinstance(output, dict):
                    messages = output.get("messages")
                    if messages and len(messages) > 0:
                        last_msg = messages[-1]
                        if hasattr(last_msg, "content") and last_msg.content:
                            full_ai_response += last_msg.content  # ë‹µë³€ ëˆ„ì 
                            data = json.dumps(
                                {"type": "answer", "content": last_msg.content},
                                ensure_ascii=False,
                            )
                            yield f"data: {data}\n\n"

            # [C] Researcher (ë¡œê·¸): ë„êµ¬ ì‚¬ìš© ì•Œë¦¼
            elif kind == "on_chat_model_end" and node_name == "researcher":
                output = event["data"].get("output")
                if output and hasattr(output, "tool_calls") and output.tool_calls:
                    tool_name = output.tool_calls[0]["name"]
                    log_msg = f"ğŸ” [ê²€ìƒ‰ ì¤‘] {tool_name} ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤..."
                    data = json.dumps(
                        {"type": "log", "content": log_msg}, ensure_ascii=False
                    )
                    yield f"data: {data}\n\n"

            # [D] Tools (ë¡œê·¸): ë°ì´í„° ì¡°íšŒ ì™„ë£Œ
            elif kind == "on_chain_end" and node_name == "tools":
                log_msg = "âœ… ë°ì´í„° ì¡°íšŒ ì™„ë£Œ! ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."
                data = json.dumps(
                    {"type": "log", "content": log_msg}, ensure_ascii=False
                )
                yield f"data: {data}\n\n"

        # [3] AI ë‹µë³€ ì™„ë£Œ í›„ DB ì €ì¥ (Assistant Turn)
        # -----------------------------------------------------------
        if full_ai_response:
            save_chat_message(thread_id, member_id, "assistant", full_ai_response)
        # -----------------------------------------------------------

    except GeneratorExit:
        print(f"ğŸ‘‹ Client disconnected (Thread: {thread_id})")
        return
    except Exception as e:
        print(f"ğŸš¨ Server Error: {e}")
        error_msg = json.dumps({"type": "error", "content": str(e)}, ensure_ascii=False)
        yield f"data: {error_msg}\n\n"


@app.get("/health")
def health():
    return {"status": "ok"}


@app.post("/chat")
async def chat_stream(request: ChatRequest):
    return StreamingResponse(
        stream_generator(request.user_query, request.thread_id, request.member_id),
        media_type="text/event-stream",
    )


# =================================================================
# ì‹ ê·œ ì¶”ê°€: ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë ¨ API
# =================================================================


@app.get("/chat/rooms/{member_id}")
async def get_rooms(member_id: int):
    """ì‚¬ìš©ìì˜ ì±„íŒ…ë°© ëª©ë¡ ì¡°íšŒ (ì‚¬ì´ë“œë°”ìš©)"""
    rooms = get_user_chat_list(member_id)
    return {"rooms": rooms}


@app.get("/chat/history/{thread_id}")
async def get_history(thread_id: str):
    """íŠ¹ì • ì±„íŒ…ë°©ì˜ ê³¼ê±° ëŒ€í™” ë‚´ì—­ ì¡°íšŒ"""
    messages = get_chat_history(thread_id)
    return {"messages": messages}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
