# backend/database.py
import os
import traceback
import json
from typing import List, Dict, Any, Optional
import psycopg2
from psycopg2.extras import RealDictCursor
from dotenv import load_dotenv
from openai import OpenAI

# ì˜¤íƒˆì ë³´ì • ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from Levenshtein import distance
except ImportError:

    def distance(s1, s2):
        return 0 if s1 == s2 else 100


load_dotenv()

# ==========================================
# 0. ì„¤ì • ë° ì´ˆê¸°í™”
# ==========================================
DB_CONFIG = {
    "dbname": os.getenv("DB_NAME", "perfume_db"),
    "user": os.getenv("DB_USER", "scentence"),
    "password": os.getenv("DB_PASSWORD", "scentence"),
    "host": os.getenv("DB_HOST", "host.docker.internal"),
    "port": os.getenv("DB_PORT", "5432"),
}

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ë¸Œëœë“œ ëª©ë¡ ìºì‹±
BRAND_CACHE = []


def get_db_connection():
    return psycopg2.connect(**DB_CONFIG)


def get_embedding(text: str) -> List[float]:
    try:
        if not text:
            return []
        return (
            client.embeddings.create(
                input=text.replace("\n", " "), model="text-embedding-3-small"
            )
            .data[0]
            .embedding
        )
    except Exception as e:
        print(f"âš ï¸ Embedding Error: {e}")
        return []


# ==========================================
# 1. ë¸Œëœë“œëª… ìë™ ë³´ì • í•¨ìˆ˜
# ==========================================
def get_all_brands() -> List[str]:
    """DBì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  ë¸Œëœë“œ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤ (ìºì‹± ì ìš©)"""
    global BRAND_CACHE
    if BRAND_CACHE:
        return BRAND_CACHE

    conn = get_db_connection()
    cur = conn.cursor()
    try:
        cur.execute("SELECT DISTINCT perfume_brand FROM TB_PERFUME_BASIC_M")
        BRAND_CACHE = [r[0] for r in cur.fetchall() if r[0]]
        return BRAND_CACHE
    finally:
        cur.close()
        conn.close()


def match_brand_name(user_input: str) -> str:
    """
    ì‚¬ìš©ì ì…ë ¥(ì˜ˆ: 'ìƒ¤ë„¬')ì„ DBì˜ ì •í™•í•œ ë¸Œëœë“œëª…(ì˜ˆ: 'Chanel')ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if not user_input:
        return user_input

    all_brands = get_all_brands()
    for b in all_brands:
        if b.lower() == user_input.lower():
            return b

    try:
        brands_str = ", ".join(all_brands)
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a specialized Brand Name Matcher. Find the exact brand name from the provided List. Return ONLY the string. If no match, return 'None'.",
                },
                {
                    "role": "user",
                    "content": f"List: [{brands_str}]\nUser Input: {user_input}",
                },
            ],
            temperature=0,
        )
        matched = response.choices[0].message.content.strip()
        if matched and matched != "None" and matched in all_brands:
            print(f"   âœ¨ Brand Correction: '{user_input}' -> '{matched}'")
            return matched
    except Exception:
        pass

    return user_input


# ==========================================
# 2. ë©”íƒ€ë°ì´í„° ë¡œë” (ì‹ ê·œ í…Œì´ë¸” ë°˜ì˜)
# ==========================================
def fetch_meta_data() -> Dict[str, str]:
    meta = {}
    conn = None
    try:
        conn = get_db_connection()
        cur = conn.cursor()

        # [ìˆ˜ì •] _R í…Œì´ë¸”ì—ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ
        cur.execute("SELECT DISTINCT season FROM TB_PERFUME_SEASON_R")
        meta["seasons"] = ", ".join([str(r[0]) for r in cur.fetchall() if r[0]])

        cur.execute("SELECT DISTINCT occasion FROM TB_PERFUME_OCA_R")
        meta["occasions"] = ", ".join([str(r[0]) for r in cur.fetchall() if r[0]])

        cur.execute("SELECT DISTINCT accord FROM TB_PERFUME_ACCORD_R LIMIT 100")
        meta["accords"] = ", ".join([str(r[0]) for r in cur.fetchall() if r[0]])

        # [ìˆ˜ì •] ì„±ë³„ì€ ê³ ì •ê°’ì´ë¯€ë¡œ í•˜ë“œì½”ë”© í˜¹ì€ Rí…Œì´ë¸” ì¡°íšŒ
        meta["genders"] = "Women, Men, Unisex"

        # Styleì€ í˜„ì¬ ë³„ë„ R í…Œì´ë¸”ì´ ì—†ìœ¼ë¯€ë¡œ Occasionì´ë‚˜ Accordë¥¼ ì°¸ê³ í•˜ê±°ë‚˜ ë¹„ì›Œë‘ 
        # ì¼ë‹¨ ë¹ˆ ë¬¸ìì—´ë¡œ ë‘¡ë‹ˆë‹¤ (í•„ìš” ì‹œ ìˆ˜ì •)
        meta["styles"] = ""

        cur.execute(
            "SELECT perfume_brand, COUNT(*) as cnt FROM TB_PERFUME_BASIC_M GROUP BY perfume_brand ORDER BY cnt DESC LIMIT 50"
        )
        top_brands = [str(r[0]) for r in cur.fetchall() if r[0]]
        meta["brands"] = ", ".join(top_brands)

    except Exception:
        meta = {}
    finally:
        if conn:
            conn.close()
    return meta


# ==========================================
# 3. Tool í•¨ìˆ˜ë“¤ (ë…¸íŠ¸ ê²€ìƒ‰)
# ==========================================
def lookup_note_by_string(keyword: str) -> List[str]:
    conn = get_db_connection()
    cur = conn.cursor()
    keyword_clean = keyword.strip().lower()
    found_notes = set()

    try:
        cur.execute(
            "SELECT note FROM TB_PERFUME_NOTES_M WHERE LOWER(note) = %s LIMIT 1",
            (keyword_clean,),
        )
        row = cur.fetchone()
        if row:
            return [row[0]]

        cur.execute("SELECT DISTINCT note FROM TB_PERFUME_NOTES_M")
        all_notes = [r[0] for r in cur.fetchall() if r[0]]

        for db_note in all_notes:
            if len(keyword_clean) < 3:
                if keyword_clean == db_note.lower():
                    found_notes.add(db_note)
                continue
            if distance(keyword_clean, db_note.lower()) <= 2:
                found_notes.add(db_note)

        return list(found_notes)
    except Exception as e:
        print(f"âš ï¸ Lookup String Note Error: {e}")
        return []
    finally:
        conn.close()


def lookup_note_by_vector(keyword: str) -> List[str]:
    conn = get_db_connection()
    cur = conn.cursor()
    try:
        query_vector = get_embedding(keyword)
        if not query_vector:
            return []
        sql = "SELECT note FROM TB_NOTE_EMBEDDING_M ORDER BY embedding <=> %s::vector LIMIT 10"
        cur.execute(sql, (query_vector,))
        return [r[0] for r in cur.fetchall()]
    except Exception as e:
        print(f"âš ï¸ Lookup Vector Note Error: {e}")
        return []
    finally:
        conn.close()


# ==========================================
# 4. ì •ë°€ ê²€ìƒ‰ ì—”ì§„ (search_perfumes)
# ==========================================
def search_perfumes(
    hard_filters: Dict[str, Any],
    strategy_filters: Dict[str, List[str]],
    exclude_ids: List[int] = None,
    limit: int = 20,  # [ìˆ˜ì •] ê¸°ë³¸ê°’ 20 (ë¦¬ë­í‚¹ ìœ„í•´ ë„‰ë„‰íˆ í™•ë³´)
) -> List[Dict[str, Any]]:

    conn = get_db_connection()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    try:
        # [ìˆ˜ì •] ë³µì¡í•œ ì—°ì‚° ì œê±°, _R í…Œì´ë¸” ì¡°íšŒ, Note ëŒ€ì†Œë¬¸ì ë³´ì •(UPPER)
        sql = """
            SELECT DISTINCT 
                m.perfume_id as id, 
                m.perfume_brand as brand, 
                m.perfume_name as name, 
                m.img_link as image_url,
                (
                    SELECT STRING_AGG(DISTINCT accord, ', ') 
                    FROM TB_PERFUME_ACCORD_R 
                    WHERE perfume_id = m.perfume_id
                ) as accords,
                (
                    SELECT gender
                    FROM TB_PERFUME_GENDER_R
                    WHERE perfume_id = m.perfume_id
                    LIMIT 1
                ) as gender,
                (SELECT STRING_AGG(DISTINCT n.note, ', ') FROM TB_PERFUME_NOTES_M n WHERE n.perfume_id = m.perfume_id AND UPPER(n.type) = 'TOP') as top_notes,
                (SELECT STRING_AGG(DISTINCT n.note, ', ') FROM TB_PERFUME_NOTES_M n WHERE n.perfume_id = m.perfume_id AND UPPER(n.type) = 'MIDDLE') as middle_notes,
                (SELECT STRING_AGG(DISTINCT n.note, ', ') FROM TB_PERFUME_NOTES_M n WHERE n.perfume_id = m.perfume_id AND UPPER(n.type) = 'BASE') as base_notes
            FROM TB_PERFUME_BASIC_M m
        """
        params = []
        where_clauses = []

        # [0] ì¤‘ë³µ ë°©ì§€
        if exclude_ids and len(exclude_ids) > 0:
            placeholders = ", ".join(["%s"] * len(exclude_ids))
            where_clauses.append(f"m.perfume_id NOT IN ({placeholders})")
            params.extend(exclude_ids)

        # ---------------------------------------------------------
        # 1. HARD FILTERS
        # ---------------------------------------------------------

        # [1-1] Gender Logic (TB_PERFUME_GENDER_R)
        gender_req = hard_filters.get("gender", "").lower()
        if gender_req:
            target_gender = ""
            if gender_req in ["women", "female"]:
                target_gender = "Feminine"
            elif gender_req in ["men", "male"]:
                target_gender = "Masculine"
            elif gender_req in ["unisex"]:
                target_gender = "Unisex"

            if target_gender:
                where_clauses.append(
                    f"m.perfume_id IN (SELECT perfume_id FROM TB_PERFUME_GENDER_R WHERE gender = %s)"
                )
                params.append(target_gender)

        # [1-2] Brand Logic
        if hard_filters.get("brand"):
            corrected_brand = match_brand_name(hard_filters["brand"])
            where_clauses.append("m.perfume_brand ILIKE %s")
            params.append(corrected_brand)

        # [1-3] Other Hard Filters
        # [ìˆ˜ì •] Occasion í…Œì´ë¸”ëª… TB_PERFUME_OCA_R ë¡œ ë³€ê²½
        hard_meta_map = {
            "season": ("TB_PERFUME_SEASON_R", "season"),
            "occasion": ("TB_PERFUME_OCA_R", "occasion"),
            "accord": ("TB_PERFUME_ACCORD_R", "accord"),
            "note": ("TB_PERFUME_NOTES_M", "note"),
        }

        for key, (table, col) in hard_meta_map.items():
            val = hard_filters.get(key)
            if not val:
                continue

            where_clauses.append(
                f"m.perfume_id IN (SELECT perfume_id FROM {table} WHERE {col} ILIKE %s)"
            )
            params.append(val)

        # ---------------------------------------------------------
        # 2. STRATEGY FILTERS
        # ---------------------------------------------------------
        # [ìˆ˜ì •] Occasion í…Œì´ë¸”ëª… TB_PERFUME_OCA_R ë¡œ ë³€ê²½
        strategy_map = {
            "accord": ("TB_PERFUME_ACCORD_R", "accord"),
            "season": ("TB_PERFUME_SEASON_R", "season"),
            "occasion": ("TB_PERFUME_OCA_R", "occasion"),
            "note": ("TB_PERFUME_NOTES_M", "note"),
        }

        for key, values in strategy_filters.items():
            if not values or key == "gender":
                continue

            mapping = strategy_map.get(key.lower())
            if not mapping:
                continue

            table_name, col_name = mapping
            category_clauses = []
            for val in values:
                category_clauses.append(
                    f"m.perfume_id IN (SELECT perfume_id FROM {table_name} WHERE {col_name} ILIKE %s)"
                )
                params.append(val)

            if category_clauses:
                where_clauses.append("(" + " OR ".join(category_clauses) + ")")

        # 3. Final Query Build
        if where_clauses:
            sql += " WHERE " + " AND ".join(where_clauses)

        # [ìˆ˜ì •] limit íŒŒë¼ë¯¸í„° ì ìš©
        sql += f" LIMIT {limit}"

        cur.execute(sql, params)
        return [dict(row) for row in cur.fetchall()]

    except Exception as e:
        print(f"ğŸš¨ DB Search Error: {e}")
        traceback.print_exc()
        return []
    finally:
        cur.close()
        conn.close()


# ==========================================
# 5. ë¦¬ë·° ê¸°ë°˜ ë¦¬ë­í‚¹ (Reranking) - [ì‹ ê·œ ì¶”ê°€]
# ==========================================
def rerank_perfumes(
    candidates: List[Dict[str, Any]], query_text: str, top_k: int = 5
) -> List[Dict[str, Any]]:
    """
    1ì°¨ ê²€ìƒ‰ëœ í›„ë³´êµ°(candidates)ì˜ ë¦¬ë·° ë²¡í„°ì™€
    ì „ëµ ì´ìœ (query_text) ë²¡í„°ë¥¼ ë¹„êµí•˜ì—¬ ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì¬ì •ë ¬í•©ë‹ˆë‹¤.
    """
    if not candidates or not query_text:
        return candidates[:top_k]

    conn = get_db_connection()
    cur = conn.cursor(cursor_factory=RealDictCursor)

    try:
        # 1. [ë²ˆì—­ & ì„ë² ë”©] í•œê¸€ ì¿¼ë¦¬ -> ì˜ë¬¸ ë²ˆì—­ (ë§¤ì¹­ ì •í™•ë„ í–¥ìƒ)
        system_prompt = """
        You are a Perfume Data Analyst.
        Your task is to convert the user's **Korean Strategic Intention** into a **Descriptive English Perfume Summary** that matches our database style.

        [Input Context]
        The input is a logical strategy (e.g., "To emphasize masculine charm...").
        
        [Output Goal]
        Transform this logic into a sensory description of a perfume that would fulfill that strategy.
        
        [Rules]
        1. **Translate & Adapt**: Translate the Korean input into English, changing the tone from "Planning" (Future tense) to "Describing" (Present tense).
           - BAD: "I will recommend a woody scent..."
           - GOOD: "This fragrance features woody notes..."
        2. **Style Matching**: Use the exact 3rd-person style found in perfume databases.
           - Start with: "This fragrance features...", "It evokes...", "It presents..."
        3. **Keyword Integration**: Naturally weave the provided keywords (e.g., Wedding, Date) into the description.
        4. **Length**: Keep it concise (2-3 sentences).

        [Example]
        Input: "ê²°í˜¼ì‹ í•˜ê°ìœ¼ë¡œ ì°¸ì„í•˜ëŠ” 20ëŒ€ ì—¬ì„±ì„ ìœ„í•´, íŠ€ì§€ ì•Šìœ¼ë©´ì„œë„ ìš°ì•„í•œ í”Œë¡œëŸ´ í–¥ì„ ì¶”ì²œí•¨. Keywords: Wedding, Elegant"
        Output: "This fragrance presents an elegant floral bouquet that is subtle yet memorable. It evokes a sophisticated vibe, making it perfect for a wedding guest who wants to maintain a polished presence."
        """

        translation_response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query_text},
            ],
            temperature=0, # ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ ìœ„í•´ 0 ì„¤ì •
        )
        
        # ë³€ìˆ˜ëª…ì„ ì˜ë¯¸ì— ë§ê²Œ 'stylized_query'ë¡œ ë³€ê²½í•˜ì—¬ ì‚¬ìš©
        stylized_query = translation_response.choices[0].message.content.strip()

        query_vector = get_embedding(stylized_query)
        if not query_vector:
            return candidates[:top_k]

        # 2. í›„ë³´êµ° ID ì¶”ì¶œ
        candidate_ids = [p["id"] for p in candidates]
        if not candidate_ids:
            return []

        # 3. ë¦¬ë­í‚¹ SQL ì‹¤í–‰
        # í›„ë³´ í–¥ìˆ˜ë“¤ì˜ ë¦¬ë·° ì¤‘, ì¿¼ë¦¬ì™€ ê°€ì¥ ìœ ì‚¬í•œ 'ì¸ìƒ ë¦¬ë·°' í•˜ë‚˜ë¥¼ ì°¾ì•„ì„œ ê·¸ ì ìˆ˜ë¡œ ì¤„ ì„¸ìš°ê¸°
        placeholders = ",".join(["%s"] * len(candidate_ids))

        sql = f"""
            SELECT 
                m.perfume_id,
                MAX(1 - (e.embedding <=> %s::vector)) as similarity_score,
                (ARRAY_AGG(m.content ORDER BY (e.embedding <=> %s::vector) ASC))[1] as best_review
            FROM TB_PERFUME_REVIEW_M m
            JOIN TB_REVIEW_EMBEDDING_M e ON m.review_id = e.review_id
            WHERE m.perfume_id IN ({placeholders})
            GROUP BY m.perfume_id
            ORDER BY similarity_score DESC
            LIMIT %s
        """

        # íŒŒë¼ë¯¸í„°: [ì¿¼ë¦¬ë²¡í„°, ì¿¼ë¦¬ë²¡í„°, IDë“¤..., limit(ë„‰ë„‰í•˜ê²Œ í›„ë³´êµ° ì „ì²´ ê°œìˆ˜ë§Œí¼)]
        params = [query_vector, query_vector] + candidate_ids + [len(candidates)]

        cur.execute(sql, params)
        scores = {row["perfume_id"]: row for row in cur.fetchall()}

        # 4. ê²°ê³¼ ì¬ì¡°ë¦½
        reranked_results = []
        for p in candidates:
            p_id = p["id"]
            if p_id in scores:
                score_data = scores[p_id]
                p["review_score"] = score_data["similarity_score"]
                p["best_review"] = score_data["best_review"]
                reranked_results.append(p)
            else:
                p["review_score"] = 0
                p["best_review"] = "ê´€ë ¨ ë¦¬ë·° ì—†ìŒ"
                reranked_results.append(p)

        # 5. ì •ë ¬ (ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ)
        reranked_results.sort(key=lambda x: x.get("review_score", 0), reverse=True)

        # [â˜…ë¡œê·¸ ì¶”ê°€] ìƒìœ„ 5ê°œ ê²°ê³¼ì˜ ìœ ì‚¬ë„ì™€ ë¦¬ë·° ìš”ì•½ ì¶œë ¥
        print(
            f"\n   ğŸ“Š [Review Reranking] Top Matches (Query: {stylized_query[:30]}...):",
            flush=True,
        )
        for i, p in enumerate(reranked_results[:5]):  # ìƒìœ„ 5ê°œë§Œ ë¡œê·¸ ì¶œë ¥
            score = p.get("review_score", 0)
            review_full = p.get("best_review", "")
            # ë¡œê·¸ ê°€ë…ì„±ì„ ìœ„í•´ ë¦¬ë·° 60ìë§Œ ìë¥´ê³  ... ì²˜ë¦¬
            review_snippet = (
                (review_full[:60] + "...") if len(review_full) > 60 else review_full
            )

            print(
                f"      {i+1}. [{score:.4f}] {p.get('brand')} - {p.get('name')} | ğŸ“ \"{review_snippet}\"",
                flush=True,
            )

        return reranked_results[:top_k]

    except Exception as e:
        print(f"ğŸš¨ Reranking Error: {e}")
        traceback.print_exc()
        return candidates[:top_k]
    finally:
        cur.close()
        conn.close()
