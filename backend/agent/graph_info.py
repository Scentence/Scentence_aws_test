# backend/agent/graph_info.py
import json
import asyncio
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, START, END

# [1] ìŠ¤í‚¤ë§ˆ ì„í¬íŠ¸
from .schemas_info import InfoState, InfoRoutingDecision
from .tools_schemas_info import IngredientAnalysisResult

# [2] ë„êµ¬ ì„í¬íŠ¸
from .tools_info import (
    lookup_perfume_info_tool,
    lookup_note_info_tool,
    lookup_accord_info_tool,
)
from .tools_similarity import lookup_similar_perfumes_tool

# [3] í”„ë¡¬í”„íŠ¸ ì„í¬íŠ¸
from .prompts_info import (
    INFO_SUPERVISOR_PROMPT,
    PERFUME_DESCRIBER_PROMPT_BEGINNER,
    PERFUME_DESCRIBER_PROMPT_EXPERT,
    SIMILARITY_CURATOR_PROMPT_BEGINNER,
    SIMILARITY_CURATOR_PROMPT_EXPERT,
    INGREDIENT_SPECIALIST_PROMPT,
)

load_dotenv()

# [LLM ì´ì›í™”]
INFO_LLM = ChatOpenAI(model="gpt-4o", temperature=0, streaming=True)
ROUTER_LLM = ChatOpenAI(model="gpt-4o", temperature=0, streaming=False)


# ==========================================
# 4. Node Functions
# ==========================================


def info_supervisor_node(state: InfoState):
    """[Router] ë¶„ë¥˜ ë…¸ë“œ"""
    print(f"\n   â–¶ï¸ [Info Subgraph] Supervisor ë…¸ë“œ ì‹œì‘", flush=True)
    user_query = state.get("user_query", "")

    chat_history = state.get("messages", [])
    context_str = ""
    if chat_history:
        recent_msgs = chat_history[-3:] if len(chat_history) > 3 else chat_history
        for msg in recent_msgs:
            role = "User" if isinstance(msg, HumanMessage) else "AI"
            if msg.content:
                context_str += f"- {role}: {msg.content}\n"

    final_system_prompt = INFO_SUPERVISOR_PROMPT
    if context_str:
        final_system_prompt += f"\n\n[Recent Chat Context]\n{context_str}"

    final_system_prompt += "\n\n[Instruction]\nResolve the target name from context and classify based on the PRIORITY rules."

    messages = [
        SystemMessage(content=final_system_prompt),
        HumanMessage(content=user_query),
    ]

    try:
        decision = ROUTER_LLM.with_structured_output(InfoRoutingDecision).invoke(
            messages
        )
        final_target = decision.target_name

        if not final_target or final_target in [
            "ì´ê±°",
            "ê·¸ê±°",
            "ì´ í–¥ìˆ˜",
            "ì¶”ì²œí•´ì¤˜",
            "ë¹„ìŠ·í•œê±°",
        ]:
            print(f"      âš ï¸ íƒ€ê²Ÿ í•´ìƒ ì‹¤íŒ¨: '{final_target}' -> Fallback", flush=True)
            return {"info_type": "unknown", "target_name": "unknown"}

        print(
            f"      ğŸ‘‰ [Decided] Type: '{decision.info_type}' | Target: '{final_target}'",
            flush=True,
        )

        return {"info_type": decision.info_type, "target_name": final_target}

    except Exception as e:
        print(f"      âŒ Supervisor ì—ëŸ¬ ë°œìƒ: {e}", flush=True)
        return {"info_type": "unknown", "target_name": "unknown"}


async def perfume_describer_node(state: InfoState):
    """[Perfume Expert] ìƒì„¸ ì •ë³´"""
    target = state["target_name"]

    # [â˜…ì„¤ì •] ì‚¬ìš©ì ëª¨ë“œ (DB ì—°ë™ ì „ í•˜ë“œì½”ë”©: "BEGINNER" or "EXPERT")
    USER_MODE = "BEGINNER"
    try:
        print(f"\n   â–¶ï¸ [Info Subgraph] Perfume Describer: '{target}'", flush=True)

        # 1. ë„êµ¬ í˜¸ì¶œ
        search_result_json = await lookup_perfume_info_tool.ainvoke(target)

        # [â˜…ì¶”ê°€] DBì—ì„œ ì‹¤ì œë¡œ ì–´ë–¤ ê°’ì´ ì™”ëŠ”ì§€ ë¡œê·¸ë¥¼ ì°ì–´ì•¼ ì›ì¸ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        print(f"      ğŸ” [DB Result]: {str(search_result_json)[:200]}...", flush=True)

        # [â˜…ìˆ˜ì •] ê°€ë“œë ˆì¼ ê°•í™”: "ê²€ìƒ‰ ì‹¤íŒ¨" ë¿ë§Œ ì•„ë‹ˆë¼ "DB ì—ëŸ¬"ë‚˜ "Error"ê°€ í¬í•¨ëœ ê²½ìš°ë„ ì°¨ë‹¨
        is_error = any(
            keyword in search_result_json
            for keyword in ["ê²€ìƒ‰ ì‹¤íŒ¨", "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "DB ì—ëŸ¬", "Error"]
        )
        is_empty = (
            not search_result_json
            or search_result_json == "{}"
            or search_result_json == "[]"
        )

        if is_error or is_empty:
            # ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ LLMì—ê²Œ ë„˜ê¸°ì§€ ì•Šê³  ì—¬ê¸°ì„œ ë°”ë¡œ ì‚¬ê³¼ ë‹µë³€ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
            fail_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{target}'ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ğŸ˜¢"
            return {"messages": [AIMessage(content=fail_msg)], "final_answer": fail_msg}

        if USER_MODE == "EXPERT":
            print("      ğŸ˜ [Mode] ì „ë¬¸ê°€ìš© ë¶„ì„ í”„ë¡¬í”„íŠ¸ ì ìš©")
            selected_prompt = PERFUME_DESCRIBER_PROMPT_EXPERT
        else:
            print("      ğŸ¥ [Mode] ë¹„ê¸°ë„ˆìš© ë„ìŠ¨íŠ¸ í”„ë¡¬í”„íŠ¸ ì ìš©")
            selected_prompt = PERFUME_DESCRIBER_PROMPT_BEGINNER

        messages = [
            SystemMessage(content=selected_prompt),
            HumanMessage(
                content=f"ëŒ€ìƒ í–¥ìˆ˜: {target}\n\n[ê²€ìƒ‰ëœ ìƒì„¸ ì •ë³´]:\n{search_result_json}"
            ),
        ]
        response = await INFO_LLM.ainvoke(messages)

        return {"messages": [response], "final_answer": response.content}

    except Exception as e:
        print(f"      âŒ Perfume Describer ì—ëŸ¬: {e}", flush=True)
        msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{target}' ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ê¸°ìˆ ì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        return {"messages": [AIMessage(content=msg)], "final_answer": msg}


async def ingredient_specialist_node(state: InfoState):
    """[Ingredient Expert] ì„±ë¶„ ë¶„ì„"""
    try:
        user_query = state.get("user_query", "")
        target_name = state.get("target_name", "")
        print(
            f"\n   â–¶ï¸ [Info Subgraph] Ingredient Specialist: '{user_query}'", flush=True
        )

        # 1. ì¿¼ë¦¬ ë¶„ì„ ë¡œì§ (ì›ë˜ ë¡œì§ ìœ ì§€)
        analysis_prompt = f"""
        You are a query analyzer. Separate 'Notes' and 'Accords'.
        Query: "{user_query}"
        Context Target: "{target_name}"
        Output JSON: {{ "notes": [], "accords": [], "is_ambiguous": false }}
        """

        try:
            analysis = await ROUTER_LLM.with_structured_output(
                IngredientAnalysisResult
            ).ainvoke(analysis_prompt, config={"tags": ["internal_helper"]})
            print(
                f"      - ë¶„ì„ ê²°ê³¼: Notes={analysis.notes}, Accords={analysis.accords}",
                flush=True,
            )
        except Exception as e:
            print(f"      âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {e}", flush=True)
            analysis = IngredientAnalysisResult(notes=[target_name], accords=[])

        # 2. ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œ (ì›ë˜ ë¡œì§ ìœ ì§€)
        tasks = []
        tasks.append(
            lookup_note_info_tool.ainvoke({"keywords": analysis.notes})
            if analysis.notes
            else asyncio.sleep(0, result="")
        )
        tasks.append(
            lookup_accord_info_tool.ainvoke({"keywords": analysis.accords})
            if analysis.accords
            else asyncio.sleep(0, result="")
        )

        results = await asyncio.gather(*tasks)
        note_result, accord_result = results[0], results[1]

        # 3. ìƒì„¸ ë¡œê¹… í•¨ìˆ˜ ë° ì‹¤í–‰ (ì›ë˜ ë¡œì§ ìœ ì§€)
        def print_result_log(category: str, result_str: str):
            if not result_str:
                return
            try:
                data = json.loads(result_str)
                if not data:
                    print(f"      ğŸ” [{category}]: ê²°ê³¼ ì—†ìŒ (Empty)", flush=True)
                    return
                for key, val in data.items():
                    if isinstance(val, dict):
                        perfumes = val.get("representative_perfumes", [])
                        perfume_log = ", ".join(perfumes) if perfumes else "ì—†ìŒ"
                        print(
                            f"      ğŸ” [{category}] '{key}': (ëŒ€í‘œí–¥ìˆ˜: {perfume_log})",
                            flush=True,
                        )
            except:
                pass

        print_result_log("Note DB", note_result)
        print_result_log("Accord DB", accord_result)

        # =============================================================
        # [â˜… í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€: ì¡°ê¸° ì°¨ë‹¨(Early Exit) ê°€ë“œë ˆì¼]
        # =============================================================
        # ë¶„ì„ëœ ë…¸íŠ¸ì™€ ì–´ì½”ë“œì— ëŒ€í•´ DB ê²€ìƒ‰ ê²°ê³¼ê°€ ëª¨ë‘ ìœ íš¨í•˜ì§€ ì•Šì€ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        # ê²°ê³¼ê°€ ì—†ê±°ë‚˜("{}"), ê²€ìƒ‰ ì‹¤íŒ¨ ë©”ì‹œì§€ê°€ í¬í•¨ëœ ê²½ìš° LLM í˜¸ì¶œì„ ìƒëµí•©ë‹ˆë‹¤.
        is_note_empty = (
            not note_result or "ê²€ìƒ‰ ì‹¤íŒ¨" in note_result or note_result == "{}"
        )
        is_accord_empty = (
            not accord_result or "ê²€ìƒ‰ ì‹¤íŒ¨" in accord_result or accord_result == "{}"
        )

        if is_note_empty and is_accord_empty:
            print(
                f"      âš ï¸ [Hallucination Guard] ë°ì´í„° ë¶€ì¬ë¡œ LLM í˜¸ì¶œì„ ìƒëµí•©ë‹ˆë‹¤.",
                flush=True,
            )
            fail_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë§ì”€í•˜ì‹  '{user_query}' ì„±ë¶„ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ê°€ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ğŸ˜¢"
            return {"messages": [AIMessage(content=fail_msg)], "final_answer": fail_msg}
        # =============================================================

        # 4. LLM ê¸°ë°˜ ë‹µë³€ ìƒì„± (ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì‹¤í–‰)
        combined_context = f"""
        [User Interest]: Notes: {analysis.notes}, Accords: {analysis.accords}
        [Search Results]:
        --- Note Data ---
        {note_result}
        --- Accord Data ---
        {accord_result}
        """

        messages = [
            SystemMessage(content=INGREDIENT_SPECIALIST_PROMPT),
            HumanMessage(content=combined_context),
        ]
        response = await INFO_LLM.ainvoke(messages)

        return {"messages": [response], "final_answer": response.content}

    except Exception as e:
        print(f"      âŒ Ingredient Specialist ì—ëŸ¬: {e}", flush=True)
        msg = "ì„±ë¶„ ì •ë³´ë¥¼ ë¶„ì„í•˜ëŠ” ë„ì¤‘ ê¸°ìˆ ì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        return {"messages": [AIMessage(content=msg)], "final_answer": msg}


async def similarity_curator_node(state: InfoState):
    """[Similarity Expert] ìœ ì‚¬ ì¶”ì²œ"""

    # [â˜…ì„¤ì •] ì‚¬ìš©ì ëª¨ë“œ
    USER_MODE = "BEGINNER"
    try:
        target = state["target_name"]
        print(f"\n   â–¶ï¸ [Info Subgraph] Similarity Curator: '{target}'", flush=True)

        # 1. ë„êµ¬ í˜¸ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        search_result_json = await lookup_similar_perfumes_tool.ainvoke(target)
        print(f"      ğŸ” [DB Result]: {str(search_result_json)[:200]}...", flush=True)

        # =============================================================
        # [â˜… í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€: ì¡°ê¸° ì°¨ë‹¨(Early Exit) ê°€ë“œë ˆì¼]
        # =============================================================
        # ìœ ì‚¬ í–¥ìˆ˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ì‹¤íŒ¨ ë©”ì‹œì§€ì¸ ê²½ìš°, LLM í˜¸ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.
        # ê²°ê³¼ê°€ "[]"ì´ê±°ë‚˜ íŠ¹ì • ì‹¤íŒ¨ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        is_empty = (
            not search_result_json
            or search_result_json == "[]"
            or "{}" in search_result_json
        )
        is_failed = (
            "ê²€ìƒ‰ ì‹¤íŒ¨" in search_result_json or "ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" in search_result_json
        )

        if is_empty or is_failed:
            print(
                f"      âš ï¸ [Hallucination Guard] ìœ ì‚¬ í–¥ìˆ˜ ë°ì´í„° ë¶€ì¬ë¡œ LLM í˜¸ì¶œì„ ìƒëµí•©ë‹ˆë‹¤.",
                flush=True,
            )
            fail_msg = f"í˜„ì¬ ì €í¬ ë°ì´í„°ë² ì´ìŠ¤ì—ëŠ” '{target}'ê³¼ ê²°ì´ ë¹„ìŠ·í•œ í–¥ìˆ˜ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë„¤ìš”. ğŸ˜… ë‹¤ë¥¸ í–¥ìˆ˜ë¡œ ë‹¤ì‹œ ì°¾ì•„ë´ ë“œë¦´ê¹Œìš”?"
            return {"messages": [AIMessage(content=fail_msg)], "final_answer": fail_msg}
        # =============================================================
        if USER_MODE == "EXPERT":
            print("      ğŸ˜ [Mode] ì „ë¬¸ê°€ìš© íë ˆì´í„° í”„ë¡¬í”„íŠ¸ ì ìš©")
            selected_prompt = SIMILARITY_CURATOR_PROMPT_EXPERT
        else:
            print("      ğŸ¥ [Mode] ë¹„ê¸°ë„ˆìš© ë„ìŠ¨íŠ¸ í”„ë¡¬í”„íŠ¸ ì ìš©")
            selected_prompt = SIMILARITY_CURATOR_PROMPT_BEGINNER

        messages = [
            SystemMessage(content=selected_prompt),
            HumanMessage(
                content=f"ì›ë³¸ í–¥ìˆ˜: {target}\n\n[ì¶”ì²œ í›„ë³´êµ° ë°ì´í„°]:\n{search_result_json}"
            ),
        ]
        response = await INFO_LLM.ainvoke(messages)

        # [â˜…ìˆ˜ì •] ê²°ê³¼ê°€ í™”ë©´ì— ë‚˜ì˜¤ë„ë¡ final_answerë¥¼ í¬í•¨í•˜ì—¬ ë°˜í™˜
        return {"messages": [response], "final_answer": response.content}

    except Exception as e:
        # ì‹œìŠ¤í…œ ì—ëŸ¬ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        print(f"      âŒ Similarity Curator ì—ëŸ¬: {e}", flush=True)
        msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. '{target}'ê³¼ ìœ ì‚¬í•œ í–¥ìˆ˜ë¥¼ ì°¾ëŠ” ê³¼ì •ì—ì„œ ê¸°ìˆ ì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        return {"messages": [AIMessage(content=msg)], "final_answer": msg}


async def fallback_handler_node(state: InfoState):
    """[Fallback] ì•ˆë‚´"""
    print(f"\n   âš ï¸ [Info Subgraph] Fallback Handler ì‹¤í–‰", flush=True)
    fallback_msg = "ì£„ì†¡í•©ë‹ˆë‹¤. ë§ì”€í•˜ì‹  í–¥ìˆ˜ê°€ ë¬´ì—‡ì¸ì§€ ì •í™•íˆ íŒŒì•…í•˜ì§€ ëª»í–ˆì–´ìš”. ğŸ˜…\n'ìƒ¤ë„¬ ë„˜ë²„5ë‘ ë¹„ìŠ·í•œ ê±° ì¶”ì²œí•´ì¤˜' ì²˜ëŸ¼ í–¥ìˆ˜ ì´ë¦„ì„ ì½• ì§‘ì–´ì„œ ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"

    # [â˜…ìˆ˜ì •] final_answer ì¶”ê°€
    return {"messages": [AIMessage(content=fallback_msg)], "final_answer": fallback_msg}


# ==========================================
# 5. Graph Build (Info Subgraph)
# ==========================================
info_workflow = StateGraph(InfoState)

info_workflow.add_node("info_supervisor", info_supervisor_node)
info_workflow.add_node("perfume_describer", perfume_describer_node)
info_workflow.add_node("ingredient_specialist", ingredient_specialist_node)
info_workflow.add_node("similarity_curator", similarity_curator_node)
info_workflow.add_node("fallback_handler", fallback_handler_node)

info_workflow.add_edge(START, "info_supervisor")

info_workflow.add_conditional_edges(
    "info_supervisor",
    lambda x: x["info_type"],
    {
        "perfume": "perfume_describer",
        "brand": "perfume_describer",
        "note": "ingredient_specialist",
        "accord": "ingredient_specialist",
        "ingredient": "ingredient_specialist",
        "similarity": "similarity_curator",
        "unknown": "fallback_handler",
    },
)

info_workflow.add_edge("perfume_describer", END)
info_workflow.add_edge("ingredient_specialist", END)
info_workflow.add_edge("similarity_curator", END)
info_workflow.add_edge("fallback_handler", END)

info_graph = info_workflow.compile()
